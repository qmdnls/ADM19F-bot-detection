In this section we will list papers that each member has read and reviewed as part of a first survey into the topic, along with a summary of their main ideas, how they can be of use for our own approach and possible shortcomings of the approach or important points not addressed by the paper.

%Table \ref{tab:symbols} gives a list of common symbols we used.
%\begin{table}[htb]
%\begin{center} 
%\begin{tabular}{|l | c | } \hline \hline 
%Symbol & Definition \\ \hline
%$N$ & number of sound-clips \\
%$D$ & average duration of a sound-clip \\
%$k$  & number of classes \\ \hline
%\end{tabular} 
%\end{center} 
%\caption{Symbols and definitions}
%\label{tab:symbols}
%\end{table} 

\subsection{Papers read by Björn Bebensee}

\subsubsection{Detecting Clusters of Fake Accounts in Online Social Networks}

\paragraph{Main idea:}
As opposed to previous literature which approaches the fake account classification problem on a per-account basis, Xiao, Freeman and Hwa~\cite{xiao2015detecting} suggest a different approach which uses an approach based on clustering instead. They suggest that as more efficient way of identifying a set of spam accounts made by a single spammer, one might classify entire clusters of users to be legitimate or fake instead of single user accounts. Furthermore their approach focuses on identifying and removing fake accounts before they can interact with legitimate users and spam the network so as to prevent damaging the experience of legitimate users. As they want to stop fake accounts as early as possible and only limited information becomes available during registration Xiao et al. focus on these few features which are available at registration time.

The authors divided their machine learning pipeline into three major parts: a cluster builder, a profile featurizer and an account scorer. The cluster builder takes a raw list of accounts and builds clusters of accounts where the clustering criteria can be simple (i.e. share a common feature) or more complex (like $k$-means). These clusters, along with the features needed for the profile featurizer, are then labelled as real or fake. If there are accounts of both groups in one cluster, it is labelled according to a threshold $x$. The featurizer extracts features from the set of accounts in one cluster to find a numerical representation (an \emph{embedding}) which can then be used by the account scorer to score the cluster. The authors test a number of models for the account scorer, specifically logistic regression, random forests and support vector machines. They find that for their use-case random forests perform best, with a recall slightly better than SVMs. Overall the model showed good performance in tests on in-sample data as well as a newer out-of-sample dataset. The authors have sinced deployed it in production at linked in and restricted more than 250,000 accounts.

\paragraph{Use for our project:}
This paper is closely related to the approach we want to take to classification of accounts as genuine or as fake. Xiao et al. suggest classifying entire clusters of users rather than single users to leverage similarities between fake accounts. This technique could prove useful for our approach and can be used in combination with features from each user's social graph. It might be possible to cluster users based on graph features such as degree, number of triangles a node participates in and others.

\paragraph{Shortcomings:} A classification of entire clusters as proposed by the authors may not perform as well if fake accounts are less homogeneous. Such a distribution of fake accounts will lead to clusters being more mixed and therefore to a higher number of false-negatives and false-positives. Additionally, this approach uses many features that only the social network operator has access to and that are not available in public datasets to cluster accounts. Unfortunately, we do not have access to this type of data and different features may prove less effective for clustering.


\subsubsection{Botnet detection using graph‐based feature clustering}

\paragraph{Main idea:}
In this paper Chowdhury et al.~\cite{chowdhury2017botnet} explore the use of graph-based features for clustering in computer networks to detect botnets. As much prior literature has focused on flow-based or rule-based detection, the authors suggest using clustering to first identify clusters of suspicious nodes. The authors are using a self-organizing map (SOM) for dimensionality reduction and clustering by assigning each node to a different cluster according to the output of the SOM. The features used for clustering are node in-degree, out-degree, in-degree weight (i.e. how many packets are received), out-degree weight (i.e. number of outgoing packets), clustering coefficient, node betweenness, and eigenvector centrality. Finally they are classifying nodes in each cluster (except the largest as it is unlikely to contain bots) starting from the smallest cluster using their own bot-search algorithm which only requires examination of few nodes for classification.
Chowdhury et al. show that their approach performs better than SVM classification on the CTU-13 dataset (a dataset of botnet traffic) using the same graph features.

\paragraph{Use for our project:}
Although the approach presented in the paper operates on an entirely different set of data, it is very similar to our goal in its nature. The authors want to identify a set of bad actors in a network given interactions between devices and given the network structure. As we are attempting to classify users in a social network according to the structure and topology of the social graph, we aim to use a set of graph-based features, similar to the features used in the paper, to cluster groups of users which we may subsequently classify jointly.

\paragraph{Shortcomings:}
Calculating all given graph features for all nodes in the graph will not scale very well. For the CTU-13 dataset used by the authors the computation took 30 hours on a supercomputer cluster. This is not an acceptable amount of processing power and time to detect social bots in social networks in (near) real-time in order to prevent interactions with real users. However, as the CTU-13 dataset contains much data and information that is not contained or necessary for an application on social graphs, some of the ideas from these paper may still be viable in our use-case. Further experimentation is required.

\subsubsection{Aiding the detection of fake accounts in large scale social online services}

\paragraph{Main idea:}
Cao, Sirivianos, Yang and Pregueiro~\cite{cao2012aiding} build on previous work in \emph{sybil detection} that aims to use random walks to identify fake accounts (\emph{sybils}) based on key observations made on the structure of social graphs. Specifically a main assumption in these fake account detection schemes is that the connectivity between real users and fake accounts is limited and lower than the number of inter-user and inter-bot connections. In this work Cao et al. propose a new algorithm called SybilRank which, unlike previous work in the field, does not aim to make a binary classification of each user account but instead focuses on creating a ranking which allows for a measure of confidence in classifications as well as further challenges like \emph{captchas} for suspicious accounts. The key idea behind this algorithm is that in a social network an early-terminated random walk starting from a real user account has a higher probability of landing at another real-user than at a fake account. Early termination is necessary for these random walks as the probability of landing at any node converges to a uniform distribution for random walks of sufficient length. The authors can thus use the degree-normalized landing probability of early-terminated random walks to rank nodes and leverage the fact that connections between real users and fake accounts are limited. They further propose a more effecient way of calculating the landing probability of random walks using power iteration.


\paragraph{Use for our project:}
Use for our project: Cao et al. show that it is possible to leverage the topology of the social graph, specifically the weak links between fake accounts and real users, to identify these fake accounts. As we plan to use binary classification for this task, it could prove helpful to include the degree-normalized landing probability for random walks as an additional graph feature either in the machine learning algorithm or for clustering of similar nodes, given that it can be computed efficiently enough which may not be the case for large-scale social networks.

\paragraph{Shortcomings:}
The authors suggest running the SybilRank algorithm periodically, i.e. once every month, which would give fake accounts a window of time that is big enough to interact with and impact real users' experience on the social network unlike the approach introduced by Xiao et al.~\cite{xiao2015detecting}.

\subsection{Papers read by Nagmat Nazarov}



\subsubsection{Towards a language independent Twitter bot detector}

\paragraph{Main idea:}
Lundberg, Nordqvist and Laitinen~\cite{lundberg2019towards} present a language-independent approach to classify single tweets as either auto-generated (AGT) or human-generated (HGT). Their classifier consists of 10 tweet features:
\begin{itemize}
    %\setlength\itemsep{0em}
    \item[a)] \emph{isReply} $\in \{ 0,1 \}$ indicates if a tweet is a reply
    \item[b)] \emph{isRetweet} $\in \{ 0,1 \}$ indicates if a tweet is a retweet
    \item[c)] \emph{accountReputation} given by number of followers divided by number of friends and followers
    \item[d)] \emph{hashtagdensity},\emph{urldensity}, \emph{mentiondensity} given by number of occurrences divided by number of words in the tweet
    \item[e)] \emph{statusesPerDay} is the number of status updates per day
    \item[f)] \emph{favoritesPerDay} is the number of tweets favorited per day
    \item[g)] \emph{deviceType} $\in \{ \text{web, mobile, app, bot, ...} \}$
\end{itemize}

The authors find that decision tree-based supervised learning algorithms work particularly well on this type of problem. Out of the evaluated algorithms, random forests (RF) perform best.

\paragraph{Use for our project:}
We may focus on decision tree-based supervised learning algorithms and particularly RF for a set of tweet features (or similarly basic profile features) like this for classification of fake accounts in online social networks.

\paragraph{Shortcomings:}
The proposed algorithm does not perform as well as single-language classifiers. If enough resources are available it may be more sensible to train a single-language classifier for each language one wants to identify auto-generated tweets in rather than using a multi-language model. The model has only been trained on a small dataset of tweets in two languages and may perform better if other languages are used as well. Furthermore, the authors evaluated the model in only one other language, more extensive evaluation may be necessary.


\subsubsection{A network topology approach to bot classification}

\paragraph{Main idea:}
Cornelissen, Barnett, Schoonwinkel, Eichstadt and Magodla are proposing a graph-based network topology approach to the bot classification problem~\cite{cornelissen2018network}. They propose utilizing the surrounding network topology of an ego in the social graph to determine whether the user is an automated agent or human. The ego graph of node $n$ is a K-2 graph obtained by a crawler, that is a graph with all nodes $i$ of distance $d(n,i) \leq 2$. Using clustering on features from the ego's graph such as the density, clustering coefficient and centrality among others, they achieve an accuracy of 70\text{\%}. The authors suggest using such network analysis in conjunction with other methods for better accuracy. 

\paragraph{Use for our project:}
The authors suggest to use centrality graph measure, for example celebrities have high indegree and low outdegree. For instance, celebrities on Twitter tend to have more people following them than they follow themselves. The authors also propose that the bots must have high outdegree but very low indegree, since most people will not follow back. We can use this proposal to distinguish the bots with non bots. ~\cite{cornelissen2018network}

\paragraph{Shortcomings:}
The false-positive rate is very high at around $\sim$45\% which is not acceptable in a real-world setting as it can potentially lead to many falsely removed accounts belonging to legitimate users, impacting the user experience negatively. However, this may be in part due to obvious outliers that have not been removed as the authors state. 


\subsubsection{Bot Classification for Real-Life Highly Class-Imbalanced Dataset}

\paragraph{Main idea:}
Typically the research on bot detection is based on particular botnet characteristics, but in this paper Sarah Harun, Tanveer Hossain Bhuiyan, Song Zhang, Hugh Medal and Linkan Bian develop three generic features to detect different types of bots regardless of specific botnet characteristics~\cite{harun2017bot}. They suggest five classification models based on those features to classify bots from a large, real-life class-imbalanced network dataset. The authors show that the generalized bot detection methods perform better than the botnet specific methods.

They first filter out unnecessary data and then extract features from the rest of data by computing the previously developed three generic features for each source-destination pair of IP addresses. In the filtering step the authors remove any IPs which never act as a source and those which perform only single communication with another device. In the feature extraction step the following features are computed: 1) Falling rate of communication frequency, 2) median communication frequency and 3) source bytes per packet for highest communication frequency. Using the extracted features the authors explore a number of different supervised learning algorithms like Quadratic Discriminant Analysis (QDA), Gaussian Naïve Bayes (GNB), Support Vector Machine (SVM), K-Nearest neighbors (KNN) and Random Forests (RF) for this highly class-imbalanced dataset. In their experiments they find that RF, KNN and even SVM perform poorly on imbalanced data and that QDA and GNB perform best for imbalanced datasets.

\paragraph{Use for our project:}
QDA and GNB perform much better than the other supervised learning algorithms on class-imbalanced data. Given such an imbalanced data distribution we should avoid using RF and KNN as these perform extremely poorly. Another important takeaway from this paper is that for accurate training of supervised models a balanced dataset is important and we should thus use such a dataset if possible.

\paragraph{Shortcomings:}
The biggest shortcoming of this paper is that it ignores passive or less active bots from the beginning. Furthermore, it is not a real-time detection system and works primarily by observing activity patterns. Although a similar approach is possible in social networks (i.e. accounts posting very frequently, sending spam links or only replies are likely to be fake accounts) but such activities can only be observed after the fact which makes this type of approach less useful in preventing fake account interactions with real users.
%I think less active bots can be initiated instead of single very active bot. Another shortcoming is that the paper does not take into account passive bots from the beginning, which may harm the real users by the time.
%what does this mean? it's not clear to me...